{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook implements the baseline preprocessing routine. This uses spacy's 'en_core_web_sm' \n",
    "model to tokenize documents, remove common English stopwords (not law-specific), and keep only\n",
    "NOUN, ADJ, ADV, and VERB parts of speech.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "raw_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/raw_data_12k'\n",
    "\n",
    "datasets = ['random_cases2', 'cases_after1950_12k', 'cases_IL_12k', 'cases_IL_after1950_12k']\n",
    "\n",
    "processed_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/baseline_12k'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "for dataset in datasets:\n",
    "    data_raw = pd.read_csv(os.path.join(raw_data_header, dataset + '_raw.csv'))\n",
    "    start = time.time()\n",
    "    opinions = []\n",
    "    print(f'Beginning preprocessing of opinions for {dataset}...')\n",
    "    for i, row in data_raw.iterrows():\n",
    "        case_id = row.case_id\n",
    "        juris = row.jurisdiction\n",
    "        text = row.opinion\n",
    "        court = row.court_name\n",
    "        if dataset=='random_cases2':\n",
    "            decision_year = pd.to_datetime(row.decision_date).year\n",
    "        else:\n",
    "            decision_year = row.decision_year\n",
    "        doc = nlp(text)\n",
    "        doc = [t for t in doc if not t.is_stop]\n",
    "        doc = [t.lemma_ for t in doc if t.pos_ in ['NOUN', 'ADJ', 'VERB', 'ADV']]\n",
    "        opinions.append((case_id, juris, court, decision_year, doc))\n",
    "        if (i+1)%1000==0:\n",
    "            print(f'Done with {i+1} opinions.')\n",
    "            print(f'Time elapsed: {round(time.time()-start)}')\n",
    "            print('#######################################')\n",
    "    print(f'Done preprocessing. Took {round(time.time()-start)} seconds.')\n",
    "\n",
    "    data_raw = None\n",
    "\n",
    "    df = pd.DataFrame(opinions, columns=['case_id', 'jurisdiction', 'court', 'decision_year', 'opinion'])\n",
    "    opinions = None\n",
    "    df.to_csv(os.path.join(processed_data_header, dataset + '_processed.csv'), index=False)\n",
    "\n",
    "    df = None\n",
    "    \n",
    "nlp = None  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
