{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook implements the preprocessing routine which prunes the list of basic legal stop words\n",
    "in addition to the baseline preprocessing tasks; moreover, only nouns are kept.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "raw_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/raw_data_12k'\n",
    "\n",
    "# Note: due to time constraints, I am only preprocessing the 'cases_IL_after1950_12k' dataset\n",
    "\n",
    "# datasets = ['random_cases2', 'cases_after1950_12k', 'cases_IL_12k', 'cases_IL_after1950_12k']\n",
    "\n",
    "datasets = ['cases_IL_after1950_12k']\n",
    "\n",
    "basic_legal_stopwords = {'a.',\n",
    " 'a.2d',\n",
    " 'a.3d',\n",
    " 'appeal',\n",
    " 'appellant',\n",
    " 'appellee',\n",
    " 'case',\n",
    " 'cir',\n",
    " 'court',\n",
    " 'defendant',\n",
    " 'f. supp.',\n",
    " 'f.supp.',\n",
    " 'f.supp.2d',\n",
    " 'f.supp.3d',\n",
    " 'fact',\n",
    " 'find',\n",
    " 'hold',\n",
    " 'judgment',\n",
    " 'n.e.',\n",
    " 'n.e.2d',\n",
    " 'opinion',\n",
    " 'order',\n",
    " 'p.',\n",
    " 'p.2d',\n",
    " 'p.3d',\n",
    " 'plaintiff',\n",
    " 'question',\n",
    " 's.e.',\n",
    " 's.e.2d',\n",
    " 's.e.3d',\n",
    " 's.w.',\n",
    " 's.w.2d',\n",
    " 's.w.3d.',\n",
    " 'see',\n",
    " 'so.',\n",
    " 'so.2d',\n",
    " 'state',\n",
    " 'time',\n",
    " 'trial'}\n",
    "\n",
    "processed_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/basic_stopwords_nouns_12k'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning preprocessing of opinions for cases_IL_after1950_12k...\n",
      "Done with 1000 opinions.\n",
      "Time elapsed: 188\n",
      "#######################################\n",
      "Done with 2000 opinions.\n",
      "Time elapsed: 379\n",
      "#######################################\n",
      "Done with 3000 opinions.\n",
      "Time elapsed: 567\n",
      "#######################################\n",
      "Done with 4000 opinions.\n",
      "Time elapsed: 754\n",
      "#######################################\n",
      "Done with 5000 opinions.\n",
      "Time elapsed: 948\n",
      "#######################################\n",
      "Done with 6000 opinions.\n",
      "Time elapsed: 1144\n",
      "#######################################\n",
      "Done with 7000 opinions.\n",
      "Time elapsed: 1342\n",
      "#######################################\n",
      "Done with 8000 opinions.\n",
      "Time elapsed: 1547\n",
      "#######################################\n",
      "Done with 9000 opinions.\n",
      "Time elapsed: 1745\n",
      "#######################################\n",
      "Done with 10000 opinions.\n",
      "Time elapsed: 1941\n",
      "#######################################\n",
      "Done with 11000 opinions.\n",
      "Time elapsed: 2130\n",
      "#######################################\n",
      "Done with 12000 opinions.\n",
      "Time elapsed: 2313\n",
      "#######################################\n",
      "Done preprocessing. Took 2313 seconds.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "for dataset in datasets:\n",
    "    data_raw = pd.read_csv(os.path.join(raw_data_header, dataset + '_raw.csv'))\n",
    "    start = time.time()\n",
    "    opinions = []\n",
    "    print(f'Beginning preprocessing of opinions for {dataset}...')\n",
    "    for i, row in data_raw.iterrows():\n",
    "        case_id = row.case_id\n",
    "        juris = row.jurisdiction\n",
    "        text = row.opinion\n",
    "        court = row.court_name\n",
    "        if dataset=='random_cases2':\n",
    "            decision_year = pd.to_datetime(row.decision_date).year\n",
    "        else:\n",
    "            decision_year = row.decision_year\n",
    "        doc = nlp(text)\n",
    "        doc = [t.lemma_ for t in doc if (t.pos_=='NOUN') and\\\n",
    "                                        (not t.is_stop) and\\\n",
    "                                        (t.lemma_ not in basic_legal_stopwords)]\n",
    "        opinions.append((case_id, juris, court, decision_year, doc))\n",
    "        if (i+1)%1000==0:\n",
    "            print(f'Done with {i+1} opinions.')\n",
    "            print(f'Time elapsed: {round(time.time()-start)}')\n",
    "            print('#######################################')\n",
    "    print(f'Done preprocessing. Took {round(time.time()-start)} seconds.')\n",
    "\n",
    "    data_raw = None\n",
    "\n",
    "    df = pd.DataFrame(opinions, columns=['case_id', 'jurisdiction', 'court', 'decision_year', 'opinion'])\n",
    "    opinions = None\n",
    "    df.to_csv(os.path.join(processed_data_header, dataset + '_processed.csv'), index=False)\n",
    "\n",
    "    df = None\n",
    "    \n",
    "nlp = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
