{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook implements the preprocessing routine which prunes the list of basic legal stop words\n",
    "in addition to the baseline preprocessing tasks, and keeps only nouns. The chosen dataset consists \n",
    "of all cases appearing in the citation graph whose jurisdiction is Illinois and whose decision dates \n",
    "occured after 1950.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "raw_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed'\n",
    "\n",
    "dataset = 'cases_IL_after1950_42k'\n",
    "\n",
    "basic_legal_stopwords = {'a.',\n",
    " 'a.2d',\n",
    " 'a.3d',\n",
    " 'appeal',\n",
    " 'appellant',\n",
    " 'appellee',\n",
    " 'case',\n",
    " 'cir',\n",
    " 'court',\n",
    " 'defendant',\n",
    " 'f. supp.',\n",
    " 'f.supp.',\n",
    " 'f.supp.2d',\n",
    " 'f.supp.3d',\n",
    " 'fact',\n",
    " 'find',\n",
    " 'hold',\n",
    " 'judgment',\n",
    " 'n.e.',\n",
    " 'n.e.2d',\n",
    " 'opinion',\n",
    " 'order',\n",
    " 'p.',\n",
    " 'p.2d',\n",
    " 'p.3d',\n",
    " 'plaintiff',\n",
    " 'question',\n",
    " 's.e.',\n",
    " 's.e.2d',\n",
    " 's.e.3d',\n",
    " 's.w.',\n",
    " 's.w.2d',\n",
    " 's.w.3d.',\n",
    " 'see',\n",
    " 'so.',\n",
    " 'so.2d',\n",
    " 'state',\n",
    " 'time',\n",
    " 'trial'}\n",
    "\n",
    "processed_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/basic_stopwords_nouns_42k'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 1000 opinions.\n",
      "Time elapsed: 194\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 2000 opinions.\n",
      "Time elapsed: 182\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 3000 opinions.\n",
      "Time elapsed: 185\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 4000 opinions.\n",
      "Time elapsed: 182\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 5000 opinions.\n",
      "Time elapsed: 180\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 6000 opinions.\n",
      "Time elapsed: 180\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 7000 opinions.\n",
      "Time elapsed: 179\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 8000 opinions.\n",
      "Time elapsed: 190\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 9000 opinions.\n",
      "Time elapsed: 186\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 10000 opinions.\n",
      "Time elapsed: 188\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 11000 opinions.\n",
      "Time elapsed: 190\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 12000 opinions.\n",
      "Time elapsed: 185\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 13000 opinions.\n",
      "Time elapsed: 179\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 14000 opinions.\n",
      "Time elapsed: 171\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 15000 opinions.\n",
      "Time elapsed: 159\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 16000 opinions.\n",
      "Time elapsed: 177\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 17000 opinions.\n",
      "Time elapsed: 164\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 18000 opinions.\n",
      "Time elapsed: 168\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 19000 opinions.\n",
      "Time elapsed: 164\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 20000 opinions.\n",
      "Time elapsed: 175\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 21000 opinions.\n",
      "Time elapsed: 167\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 22000 opinions.\n",
      "Time elapsed: 168\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 23000 opinions.\n",
      "Time elapsed: 167\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 24000 opinions.\n",
      "Time elapsed: 159\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 25000 opinions.\n",
      "Time elapsed: 166\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 26000 opinions.\n",
      "Time elapsed: 164\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 27000 opinions.\n",
      "Time elapsed: 174\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 28000 opinions.\n",
      "Time elapsed: 168\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 29000 opinions.\n",
      "Time elapsed: 169\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 30000 opinions.\n",
      "Time elapsed: 156\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 31000 opinions.\n",
      "Time elapsed: 164\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 32000 opinions.\n",
      "Time elapsed: 162\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 33000 opinions.\n",
      "Time elapsed: 163\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 34000 opinions.\n",
      "Time elapsed: 164\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 35000 opinions.\n",
      "Time elapsed: 164\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 36000 opinions.\n",
      "Time elapsed: 175\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 37000 opinions.\n",
      "Time elapsed: 165\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 38000 opinions.\n",
      "Time elapsed: 169\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 39000 opinions.\n",
      "Time elapsed: 165\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 40000 opinions.\n",
      "Time elapsed: 165\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 41000 opinions.\n",
      "Time elapsed: 167\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 42000 opinions.\n",
      "Time elapsed: 164\n",
      "#######################################\n",
      "Beginning preprocessing of opinions for cases_IL_after1950_42k...\n",
      "Done with 43000 opinions.\n",
      "Time elapsed: 76\n",
      "#######################################\n",
      "Done preprocessing. Took 76 seconds.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "reader = pd.read_csv(os.path.join(raw_data_header, dataset + '_raw.csv'), chunksize=1000)\n",
    "i = 1\n",
    "for data_raw in reader:\n",
    "    start = time.time()\n",
    "    opinions = []\n",
    "    print(f'Beginning preprocessing of opinions for {dataset}...')\n",
    "    for _, row in data_raw.iterrows():\n",
    "        case_id = row.case_id\n",
    "        juris = row.jurisdiction\n",
    "        text = row.opinion\n",
    "        court = row.court_name\n",
    "        decision_year = row.decision_year\n",
    "        doc = nlp(text)\n",
    "        doc = [t.lemma_ for t in doc if (t.pos_ =='NOUN') and\\\n",
    "                                        (not t.is_stop) and\\\n",
    "                                        (t.lemma_ not in basic_legal_stopwords)]\n",
    "        opinions.append((case_id, juris, court, decision_year, doc))\n",
    "    df = pd.DataFrame(opinions, columns=['case_id', 'jurisdiction', 'court', 'decision_year', 'opinion'])\n",
    "    opinions = None\n",
    "    if i==1:\n",
    "        df.to_csv(os.path.join(processed_data_header, dataset + '_processed.csv'), index=False)\n",
    "    else:\n",
    "        df.to_csv(os.path.join(processed_data_header, dataset + '_processed.csv'), index=False,\n",
    "                 mode = 'a')\n",
    "    df = None\n",
    "    print(f'Done with {i*1000} opinions.')\n",
    "    print(f'Time elapsed: {round(time.time()-start)}')\n",
    "    i+=1\n",
    "    print('#######################################')\n",
    "\n",
    "print(f'Done preprocessing. Took {round(time.time()-start)} seconds.')\n",
    "\n",
    "    \n",
    "nlp = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this notebook we train, validate, and visualize different topic models for the basic_stopwords\n",
    "preprocessing routine. The chosen dataset consists of all cases appearing in the citation graph\n",
    "whose jurisdiction is Illinois and whose decision dates occured after 1950.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "processed_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/basic_stopwords_42k'\n",
    "\n",
    "datasets = ['cases_IL_after1950_42k']\n",
    "\n",
    "graph_path = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/citation_graph.gpickle'\n",
    "\n",
    "output_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/validation_output/basic_stopwords_42k'\n",
    "\n",
    "wordcloud_header_top = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/wordclouds/basic_stopwords_42k'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list_col(df, col_to_parse):\n",
    "    df.loc[:, col_to_parse] = df[col_to_parse].apply(lambda x: x.strip('[]').split(','))\n",
    "    df.loc[:, col_to_parse] = df[col_to_parse].apply(lambda x: [t.strip().strip(\"'\") for t in x])\n",
    "    \n",
    "# HELPER FUNCTIONS FOR PERPLEXITY, COHERENCE, AND WORDCLOUDS\n",
    "def get_perplexity(model, corpus):\n",
    "    return 2**(-model.log_perplexity(corpus))\n",
    "\n",
    "def get_coherence(model, texts, dictionary):\n",
    "    # texts should be lists of terms, not the BoW representation\n",
    "    coherence_model = CoherenceModel(model=model, texts=texts, \n",
    "                                 dictionary=dictionary, coherence='c_v')\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def get_wordclouds(model, num_words=250, save_file=None, num_topics=10):\n",
    "    for i, topic in  enumerate(model.show_topics(num_topics=num_topics, num_words=num_words, formatted=False)):\n",
    "        topic_dict = {w:v for (w,v) in topic[1]}\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800, \n",
    "                        background_color ='white',\n",
    "                        min_font_size = 10).generate_from_frequencies(topic_dict) \n",
    "\n",
    "        # plot the WordCloud image                        \n",
    "        plt.figure(figsize = (8, 8), facecolor = None) \n",
    "        plt.imshow(wordcloud) \n",
    "        plt.axis(\"off\") \n",
    "        plt.tight_layout(pad = 0) \n",
    "        if save_file:\n",
    "            path = os.path.join(save_file, f'topic_{i+1}.png')\n",
    "            plt.savefig(path)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "# HELPER FUNCTIONS FOR CITATION-GRAPH KNN VALIDATION\n",
    "\n",
    "def unpack_topics(df, num_topics):\n",
    "    new_df = pd.DataFrame(columns=['case_id']+[f'topic_{i}' for i in range(num_topics)])\n",
    "    for i, row in df.iterrows():\n",
    "        new_row = {}\n",
    "        new_row['case_id'] = row.case_id\n",
    "        topics = row.topic_vector\n",
    "        for t in topics:\n",
    "            topic_num = t[0]\n",
    "            topic_val = t[1]\n",
    "            new_row[f'topic_{topic_num}'] = topic_val\n",
    "        new_df = new_df.append(new_row, ignore_index=True)\n",
    "    new_df = new_df.fillna(0)\n",
    "    new_df['case_id'] = new_df['case_id'].apply(lambda x: int(x))\n",
    "    return new_df\n",
    "\n",
    "def get_nearest_neighbors(df, n_neighbors, nn_model):\n",
    "    knearest = nn_model.kneighbors(n_neighbors=n_neighbors, return_distance=False)\n",
    "    for k in range(n_neighbors):\n",
    "        df[f'nn_{k}'] = [df.case_id[x[k]] for x in knearest]\n",
    "        \n",
    "def edge_length(row, k, graph):\n",
    "    return nx.shortest_path_length(graph, row['case_id'], row[f'nn_{k}'])\n",
    "\n",
    "def get_edge_lengths(df, n_neighbors, graph):\n",
    "    for k in range(n_neighbors):\n",
    "        df[f'cite_distance_{k}'] = df.apply(edge_length, k=k, graph=graph, axis=1)\n",
    "        \n",
    "def get_min_cite_dist(row, n_neighbors):\n",
    "    return int(row[[f'cite_distance_{k}' for k in range(n_neighbors)]].min())\n",
    "\n",
    "def get_mean_cite_dist(row, n_neighbors):\n",
    "    return row[[f'cite_distance_{k}' for k in range(n_neighbors)]].mean()\n",
    "\n",
    "def get_max_cite_dist(row, n_neighbors):\n",
    "    return int(row[[f'cite_distance_{k}' for k in range(n_neighbors)]].max())\n",
    "\n",
    "def knn_citation_validation(test_ids, lda_model, test_corpus, graph, n_neighbors):\n",
    "    test_data = pd.DataFrame(test_ids, columns=['case_id'])\n",
    "    test_data['topic_vector'] = [lda_model[op] for op in test_corpus]\n",
    "    nodes = list(graph.nodes)\n",
    "    test_data = test_data.loc[test_data.case_id.isin(nodes),:]\n",
    "    nodes = None\n",
    "    test_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    test_data = unpack_topics(test_data, num_topics=15)\n",
    "    \n",
    "    nn = NearestNeighbors()\n",
    "\n",
    "    X = test_data.drop(columns='case_id').values\n",
    "\n",
    "    nn.fit(X)\n",
    "    \n",
    "    get_nearest_neighbors(test_data, n_neighbors, nn)\n",
    "    \n",
    "    get_edge_lengths(test_data, n_neighbors, graph)\n",
    "    \n",
    "    test_data['min_cite_dist'] = test_data.apply(get_min_cite_dist, axis=1, n_neighbors=n_neighbors)\n",
    "    test_data['mean_cite_dist'] = test_data.apply(get_mean_cite_dist, axis=1, n_neighbors=n_neighbors)\n",
    "    test_data['max_cite_dist'] = test_data.apply(get_max_cite_dist, axis=1, n_neighbors=n_neighbors)\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain largest connected component of citation graph and other static variables.\n",
    "\n",
    "G = nx.read_gpickle(graph_path)\n",
    "big_subgraph = nx.subgraph(G, list(nx.connected_components(G))[0])\n",
    "G = None\n",
    "seed = 9\n",
    "num_topics = [5, 8, 10, 12, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING VALIDATION OF cases_IL_after1950_42k...\n",
      "Processing model with 5 topics...\n",
      "Model training done. Time: 76\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 36\n",
      "Computing coherence on test set.\n",
      "Done. Time: 109\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 114\n",
      "Saving wordclouds...\n",
      "Done. Time: 20\n",
      "Done with full iteration. TOTAL TIME: 355\n",
      "######################################\n",
      "Processing model with 8 topics...\n",
      "Model training done. Time: 76\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 37\n",
      "Computing coherence on test set.\n",
      "Done. Time: 83\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 105\n",
      "Saving wordclouds...\n",
      "Done. Time: 24\n",
      "Done with full iteration. TOTAL TIME: 324\n",
      "######################################\n",
      "Processing model with 10 topics...\n",
      "Model training done. Time: 77\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 36\n",
      "Computing coherence on test set.\n",
      "Done. Time: 85\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 105\n",
      "Saving wordclouds...\n",
      "Done. Time: 24\n",
      "Done with full iteration. TOTAL TIME: 327\n",
      "######################################\n",
      "Processing model with 12 topics...\n",
      "Model training done. Time: 77\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 36\n",
      "Computing coherence on test set.\n",
      "Done. Time: 89\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 103\n",
      "Saving wordclouds...\n",
      "Done. Time: 84\n",
      "Done with full iteration. TOTAL TIME: 389\n",
      "######################################\n",
      "Processing model with 15 topics...\n",
      "Model training done. Time: 80\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 37\n",
      "Computing coherence on test set.\n",
      "Done. Time: 106\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 102\n",
      "Saving wordclouds...\n",
      "Done. Time: 36\n",
      "Done with full iteration. TOTAL TIME: 361\n",
      "######################################\n",
      "FINISHED. TOTAL TIME ELAPSED: 1754.6159882545471\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(f'BEGINNING VALIDATION OF {dataset}...')\n",
    "    data = pd.read_csv(os.path.join(processed_data_header, dataset + '_processed.csv'))\n",
    "    data = data.loc[data.case_id!='case_id',:]\n",
    "    data.loc[:,'case_id'] = data.case_id.apply(lambda x: int(x))\n",
    "    parse_list_col(data, 'opinion')\n",
    "    \n",
    "    # Shuffle data to ensure jurisdictions are mixed properly.\n",
    "\n",
    "    data = data.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # Split into train/test sets\n",
    "\n",
    "    split = int(0.8*data.shape[0])\n",
    "    train_ops = data.loc[:split, 'opinion']\n",
    "    test_ops = data.loc[split:, 'opinion']\n",
    "\n",
    "    # Build gensim dictionary\n",
    "\n",
    "    op_dictionary = Dictionary(train_ops.to_list())\n",
    "    train_op_corpus = [op_dictionary.doc2bow(op) for op in train_ops.to_list()]\n",
    "    test_op_corpus = [op_dictionary.doc2bow(op) for op in test_ops.to_list()]\n",
    "    \n",
    "    # BEGIN VALIDATION. THIS WILL TAKE SOME TIME.\n",
    "\n",
    "    train_perplexity = []\n",
    "    test_perplexity = []\n",
    "    train_coherence = []\n",
    "    test_coherence = []\n",
    "    min_cite_dist_mean = []\n",
    "    min_cite_dist_sd = []\n",
    "    avg_cite_dist_mean = []\n",
    "    avg_cite_dist_sd = []\n",
    "    max_cite_dist_mean = []\n",
    "    max_cite_dist_sd = []\n",
    "\n",
    "    test_ids = data.loc[split:, 'case_id'].to_list()\n",
    "    data = None\n",
    "\n",
    "    wordcloud_header = os.path.join(wordcloud_header_top, dataset)\n",
    "    os.mkdir(wordcloud_header)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for nt in num_topics:\n",
    "        iter_start=time.time()\n",
    "        print(f'Processing model with {nt} topics...')\n",
    "        temp_time= time.time()\n",
    "        lda = LdaModel(train_op_corpus, id2word=op_dictionary, num_topics=nt)\n",
    "        print(f'Model training done. Time: {round(time.time()-temp_time)}')\n",
    "        # print('Computing perplexity on train set.')\n",
    "        # temp_time= time.time()\n",
    "        # train_perplexity.append(get_perplexity(lda, train_op_corpus))\n",
    "        # print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing perplexity on test set.')\n",
    "        temp_time= time.time()\n",
    "        test_perplexity.append(get_perplexity(lda, test_op_corpus))\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        # print('Computing coherence on train set.')\n",
    "        # temp_time= time.time()\n",
    "        # train_coherence.append(get_coherence(lda, train_ops.to_list(), op_dictionary))\n",
    "        # print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing coherence on test set.')\n",
    "        temp_time= time.time()\n",
    "        test_coherence.append(get_coherence(lda, test_ops.to_list(), op_dictionary))\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing citation graph validation metrics.')\n",
    "        temp_time= time.time()\n",
    "        metric_cols = ['min_cite_dist', 'mean_cite_dist', 'max_cite_dist']\n",
    "        citation_dist_results = knn_citation_validation(test_ids, lda, test_op_corpus, big_subgraph, 5)[metric_cols]\n",
    "        min_cite_dist_mean.append(citation_dist_results.min_cite_dist.mean())\n",
    "        min_cite_dist_sd.append(citation_dist_results.min_cite_dist.std())\n",
    "        avg_cite_dist_mean.append(citation_dist_results.mean_cite_dist.mean())\n",
    "        avg_cite_dist_sd.append(citation_dist_results.mean_cite_dist.std())\n",
    "        max_cite_dist_mean.append(citation_dist_results.max_cite_dist.mean())\n",
    "        max_cite_dist_sd.append(citation_dist_results.max_cite_dist.std())\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Saving wordclouds...')\n",
    "        temp_time= time.time()\n",
    "        os.mkdir(os.path.join(wordcloud_header, f'num_topics_{nt}'))\n",
    "        get_wordclouds(lda, save_file=os.path.join(wordcloud_header, f'num_topics_{nt}'), num_topics=nt)\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print(f'Done with full iteration. TOTAL TIME: {round(time.time()-iter_start)}')\n",
    "        print('######################################')\n",
    "    print(f'FINISHED. TOTAL TIME ELAPSED: {time.time()-start}')\n",
    "\n",
    "    results_df = pd.DataFrame({'num_topics': num_topics,\n",
    "                              'test_perplexity': test_perplexity,\n",
    "                              'test_coherence': test_coherence,\n",
    "                              'min_cite_dist_mean': min_cite_dist_mean,\n",
    "                              'min_cite_dist_sd': min_cite_dist_sd,\n",
    "                              'avg_cite_dist_mean': avg_cite_dist_mean,\n",
    "                              'avg_cite_dist_sd': avg_cite_dist_sd,\n",
    "                              'max_cite_dist_mean': max_cite_dist_mean,\n",
    "                              'max_cite_dist_sd': max_cite_dist_sd})\n",
    "\n",
    "    results_df.to_csv(os.path.join(output_header, dataset + '.csv'), index=False)\n",
    "\n",
    "    train_ops = None\n",
    "    train_op_corpus = None\n",
    "    test_ops = None\n",
    "    test_op_corpus = None\n",
    "    op_dictionary = None\n",
    "    test_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this notebook we train, validate, and visualize different topic models for the basic_stopwords\n",
    "preprocessing routine with only nouns. The chosen dataset consists of all cases appearing in the \n",
    "citation graph whose jurisdiction is Illinois and whose decision dates occured after 1950.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "processed_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/basic_stopwords_nouns_42k'\n",
    "\n",
    "datasets = ['cases_IL_after1950_42k']\n",
    "\n",
    "graph_path = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/citation_graph.gpickle'\n",
    "\n",
    "output_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/validation_output/basic_stopwords_nouns_42k'\n",
    "\n",
    "wordcloud_header_top = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/wordclouds/basic_stopwords_nouns_42k'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEGINNING VALIDATION OF cases_IL_after1950_42k...\n",
      "Processing model with 5 topics...\n",
      "Model training done. Time: 52\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 19\n",
      "Computing coherence on test set.\n",
      "Done. Time: 38\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 111\n",
      "Saving wordclouds...\n",
      "Done. Time: 13\n",
      "Done with full iteration. TOTAL TIME: 233\n",
      "######################################\n",
      "Processing model with 8 topics...\n",
      "Model training done. Time: 54\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 20\n",
      "Computing coherence on test set.\n",
      "Done. Time: 46\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 108\n",
      "Saving wordclouds...\n",
      "Done. Time: 21\n",
      "Done with full iteration. TOTAL TIME: 248\n",
      "######################################\n",
      "Processing model with 10 topics...\n",
      "Model training done. Time: 54\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 20\n",
      "Computing coherence on test set.\n",
      "Done. Time: 65\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 107\n",
      "Saving wordclouds...\n",
      "Done. Time: 24\n",
      "Done with full iteration. TOTAL TIME: 271\n",
      "######################################\n",
      "Processing model with 12 topics...\n",
      "Model training done. Time: 54\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 20\n",
      "Computing coherence on test set.\n",
      "Done. Time: 55\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 106\n",
      "Saving wordclouds...\n",
      "Done. Time: 28\n",
      "Done with full iteration. TOTAL TIME: 264\n",
      "######################################\n",
      "Processing model with 15 topics...\n",
      "Model training done. Time: 58\n",
      "Computing perplexity on test set.\n",
      "Done. Time: 21\n",
      "Computing coherence on test set.\n",
      "Done. Time: 66\n",
      "Computing citation graph validation metrics.\n",
      "Done. Time: 105\n",
      "Saving wordclouds...\n",
      "Done. Time: 37\n",
      "Done with full iteration. TOTAL TIME: 286\n",
      "######################################\n",
      "FINISHED. TOTAL TIME ELAPSED: 1301.7357249259949\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print(f'BEGINNING VALIDATION OF {dataset}...')\n",
    "    data = pd.read_csv(os.path.join(processed_data_header, dataset + '_processed.csv'))\n",
    "    data = data.loc[data.case_id!='case_id',:]\n",
    "    data.loc[:,'case_id'] = data.case_id.apply(lambda x: int(x))\n",
    "    parse_list_col(data, 'opinion')\n",
    "    \n",
    "    # Shuffle data to ensure jurisdictions are mixed properly.\n",
    "\n",
    "    data = data.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # Split into train/test sets\n",
    "\n",
    "    split = int(0.8*data.shape[0])\n",
    "    train_ops = data.loc[:split, 'opinion']\n",
    "    test_ops = data.loc[split:, 'opinion']\n",
    "\n",
    "    # Build gensim dictionary\n",
    "\n",
    "    op_dictionary = Dictionary(train_ops.to_list())\n",
    "    train_op_corpus = [op_dictionary.doc2bow(op) for op in train_ops.to_list()]\n",
    "    test_op_corpus = [op_dictionary.doc2bow(op) for op in test_ops.to_list()]\n",
    "    \n",
    "    # BEGIN VALIDATION. THIS WILL TAKE SOME TIME.\n",
    "\n",
    "    train_perplexity = []\n",
    "    test_perplexity = []\n",
    "    train_coherence = []\n",
    "    test_coherence = []\n",
    "    min_cite_dist_mean = []\n",
    "    min_cite_dist_sd = []\n",
    "    avg_cite_dist_mean = []\n",
    "    avg_cite_dist_sd = []\n",
    "    max_cite_dist_mean = []\n",
    "    max_cite_dist_sd = []\n",
    "\n",
    "    test_ids = data.loc[split:, 'case_id'].to_list()\n",
    "    data = None\n",
    "\n",
    "    wordcloud_header = os.path.join(wordcloud_header_top, dataset)\n",
    "    os.mkdir(wordcloud_header)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for nt in num_topics:\n",
    "        iter_start=time.time()\n",
    "        print(f'Processing model with {nt} topics...')\n",
    "        temp_time= time.time()\n",
    "        lda = LdaModel(train_op_corpus, id2word=op_dictionary, num_topics=nt)\n",
    "        print(f'Model training done. Time: {round(time.time()-temp_time)}')\n",
    "        # print('Computing perplexity on train set.')\n",
    "        # temp_time= time.time()\n",
    "        # train_perplexity.append(get_perplexity(lda, train_op_corpus))\n",
    "        # print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing perplexity on test set.')\n",
    "        temp_time= time.time()\n",
    "        test_perplexity.append(get_perplexity(lda, test_op_corpus))\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        # print('Computing coherence on train set.')\n",
    "        # temp_time= time.time()\n",
    "        # train_coherence.append(get_coherence(lda, train_ops.to_list(), op_dictionary))\n",
    "        # print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing coherence on test set.')\n",
    "        temp_time= time.time()\n",
    "        test_coherence.append(get_coherence(lda, test_ops.to_list(), op_dictionary))\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing citation graph validation metrics.')\n",
    "        temp_time= time.time()\n",
    "        metric_cols = ['min_cite_dist', 'mean_cite_dist', 'max_cite_dist']\n",
    "        citation_dist_results = knn_citation_validation(test_ids, lda, test_op_corpus, big_subgraph, 5)[metric_cols]\n",
    "        min_cite_dist_mean.append(citation_dist_results.min_cite_dist.mean())\n",
    "        min_cite_dist_sd.append(citation_dist_results.min_cite_dist.std())\n",
    "        avg_cite_dist_mean.append(citation_dist_results.mean_cite_dist.mean())\n",
    "        avg_cite_dist_sd.append(citation_dist_results.mean_cite_dist.std())\n",
    "        max_cite_dist_mean.append(citation_dist_results.max_cite_dist.mean())\n",
    "        max_cite_dist_sd.append(citation_dist_results.max_cite_dist.std())\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Saving wordclouds...')\n",
    "        temp_time= time.time()\n",
    "        os.mkdir(os.path.join(wordcloud_header, f'num_topics_{nt}'))\n",
    "        get_wordclouds(lda, save_file=os.path.join(wordcloud_header, f'num_topics_{nt}'), num_topics=nt)\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print(f'Done with full iteration. TOTAL TIME: {round(time.time()-iter_start)}')\n",
    "        print('######################################')\n",
    "    print(f'FINISHED. TOTAL TIME ELAPSED: {time.time()-start}')\n",
    "\n",
    "    results_df = pd.DataFrame({'num_topics': num_topics,\n",
    "                              'test_perplexity': test_perplexity,\n",
    "                              'test_coherence': test_coherence,\n",
    "                              'min_cite_dist_mean': min_cite_dist_mean,\n",
    "                              'min_cite_dist_sd': min_cite_dist_sd,\n",
    "                              'avg_cite_dist_mean': avg_cite_dist_mean,\n",
    "                              'avg_cite_dist_sd': avg_cite_dist_sd,\n",
    "                              'max_cite_dist_mean': max_cite_dist_mean,\n",
    "                              'max_cite_dist_sd': max_cite_dist_sd})\n",
    "\n",
    "    results_df.to_csv(os.path.join(output_header, dataset + '.csv'), index=False)\n",
    "\n",
    "    train_ops = None\n",
    "    train_op_corpus = None\n",
    "    test_ops = None\n",
    "    test_op_corpus = None\n",
    "    op_dictionary = None\n",
    "    test_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
