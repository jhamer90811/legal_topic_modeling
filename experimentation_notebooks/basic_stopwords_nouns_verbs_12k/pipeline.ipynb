{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook implements the preprocessing routine which prunes the list of basic legal stop words\n",
    "in addition to the baseline preprocessing tasks; moreover, only nouns and verbs are kept.\n",
    "\n",
    "We examine only the 12k dataset of Illinois cases from after 1950.\n",
    "\n",
    "If other small datasets (<15k rows) need to be preprocessed/analyzed, change the \"datasets\" variable below.\n",
    "\n",
    "After preprocessing we train topic models with 5, 8, 10, 12, and 15 topics and compute coherence, perplexity, and the\n",
    "citation-similarity metric.\n",
    "\n",
    "Comparison of different datasets can be performed in the last section.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import spacy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "raw_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/raw_data_12k'\n",
    "\n",
    "# Note: due to time constraints, I am only preprocessing the 'cases_IL_after1950_12k' dataset\n",
    "\n",
    "# datasets = ['random_cases2', 'cases_after1950_12k', 'cases_IL_12k', 'cases_IL_after1950_12k']\n",
    "\n",
    "datasets = ['cases_IL_after1950_12k']\n",
    "\n",
    "basic_legal_stopwords = {'a.',\n",
    " 'a.2d',\n",
    " 'a.3d',\n",
    " 'appeal',\n",
    " 'appellant',\n",
    " 'appellee',\n",
    " 'case',\n",
    " 'cir',\n",
    " 'court',\n",
    " 'defendant',\n",
    " 'f. supp.',\n",
    " 'f.supp.',\n",
    " 'f.supp.2d',\n",
    " 'f.supp.3d',\n",
    " 'fact',\n",
    " 'find',\n",
    " 'hold',\n",
    " 'judgment',\n",
    " 'n.e.',\n",
    " 'n.e.2d',\n",
    " 'opinion',\n",
    " 'order',\n",
    " 'p.',\n",
    " 'p.2d',\n",
    " 'p.3d',\n",
    " 'plaintiff',\n",
    " 'question',\n",
    " 's.e.',\n",
    " 's.e.2d',\n",
    " 's.e.3d',\n",
    " 's.w.',\n",
    " 's.w.2d',\n",
    " 's.w.3d.',\n",
    " 'see',\n",
    " 'so.',\n",
    " 'so.2d',\n",
    " 'state',\n",
    " 'time',\n",
    " 'trial'}\n",
    "\n",
    "processed_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/basic_stopwords_nouns_verbs_12k'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSOR\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "for dataset in datasets:\n",
    "    data_raw = pd.read_csv(os.path.join(raw_data_header, dataset + '_raw.csv'))\n",
    "    start = time.time()\n",
    "    opinions = []\n",
    "    print(f'Beginning preprocessing of opinions for {dataset}...')\n",
    "    for i, row in data_raw.iterrows():\n",
    "        case_id = row.case_id\n",
    "        juris = row.jurisdiction\n",
    "        text = row.opinion\n",
    "        court = row.court_name\n",
    "        if dataset=='random_cases2':\n",
    "            decision_year = pd.to_datetime(row.decision_date).year\n",
    "        else:\n",
    "            decision_year = row.decision_year\n",
    "        doc = nlp(text)\n",
    "        doc = [t.lemma_ for t in doc if (t.pos_ in ['NOUN','VERB']) and\\\n",
    "                                        (not t.is_stop) and\\\n",
    "                                        (t.lemma_ not in basic_legal_stopwords)]\n",
    "        opinions.append((case_id, juris, court, decision_year, doc))\n",
    "        if (i+1)%1000==0:\n",
    "            print(f'Done with {i+1} opinions.')\n",
    "            print(f'Time elapsed: {round(time.time()-start)}')\n",
    "            print('#######################################')\n",
    "    print(f'Done preprocessing. Took {round(time.time()-start)} seconds.')\n",
    "\n",
    "    data_raw = None\n",
    "\n",
    "    df = pd.DataFrame(opinions, columns=['case_id', 'jurisdiction', 'court', 'decision_year', 'opinion'])\n",
    "    opinions = None\n",
    "    df.to_csv(os.path.join(processed_data_header, dataset + '_processed.csv'), index=False)\n",
    "\n",
    "    df = None\n",
    "    \n",
    "nlp = None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPIC MODELING SET UP\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "processed_data_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/data_uncompressed/basic_stopwords_nouns_verbs_12k'\n",
    "\n",
    "# Note: due to time constraints, I am only preprocessing the 'cases_IL_after1950_12k' dataset\n",
    "\n",
    "# datasets = ['random_cases2', 'cases_after1950_12k', 'cases_IL_12k', 'cases_IL_after1950_12k']\n",
    "\n",
    "datasets = ['cases_IL_after1950_12k']\n",
    "\n",
    "graph_path = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/citation_graph.gpickle'\n",
    "\n",
    "output_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/validation_output/basic_stopwords_nouns_verbs_12k'\n",
    "\n",
    "wordcloud_header_top = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/wordclouds/basic_stopwords_nouns_verbs_12k'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPIC MODELING HELPER FUNCTIONS\n",
    "\n",
    "def parse_list_col(df, col_to_parse):\n",
    "    df.loc[:, col_to_parse] = df[col_to_parse].apply(lambda x: x.strip('[]').split(','))\n",
    "    df.loc[:, col_to_parse] = df[col_to_parse].apply(lambda x: [t.strip().strip(\"'\") for t in x])\n",
    "    \n",
    "# HELPER FUNCTIONS FOR PERPLEXITY, COHERENCE, AND WORDCLOUDS\n",
    "def get_perplexity(model, corpus):\n",
    "    return 2**(-model.log_perplexity(corpus))\n",
    "\n",
    "def get_coherence(model, texts, dictionary):\n",
    "    # texts should be lists of terms, not the BoW representation\n",
    "    coherence_model = CoherenceModel(model=model, texts=texts, \n",
    "                                 dictionary=dictionary, coherence='c_v')\n",
    "    return coherence_model.get_coherence()\n",
    "\n",
    "def get_wordclouds(model, num_words=250, save_file=None, num_topics=10):\n",
    "    for i, topic in  enumerate(model.show_topics(num_topics=num_topics, num_words=num_words, formatted=False)):\n",
    "        topic_dict = {w:v for (w,v) in topic[1]}\n",
    "\n",
    "        wordcloud = WordCloud(width = 800, height = 800, \n",
    "                        background_color ='white',\n",
    "                        min_font_size = 10).generate_from_frequencies(topic_dict) \n",
    "\n",
    "        # plot the WordCloud image                        \n",
    "        plt.figure(figsize = (8, 8), facecolor = None) \n",
    "        plt.imshow(wordcloud) \n",
    "        plt.axis(\"off\") \n",
    "        plt.tight_layout(pad = 0) \n",
    "        if save_file:\n",
    "            path = os.path.join(save_file, f'topic_{i+1}.png')\n",
    "            plt.savefig(path)\n",
    "            plt.close()\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "# HELPER FUNCTIONS FOR CITATION-GRAPH KNN VALIDATION\n",
    "\n",
    "def unpack_topics(df, num_topics):\n",
    "    new_df = pd.DataFrame(columns=['case_id']+[f'topic_{i}' for i in range(num_topics)])\n",
    "    for i, row in df.iterrows():\n",
    "        new_row = {}\n",
    "        new_row['case_id'] = row.case_id\n",
    "        topics = row.topic_vector\n",
    "        for t in topics:\n",
    "            topic_num = t[0]\n",
    "            topic_val = t[1]\n",
    "            new_row[f'topic_{topic_num}'] = topic_val\n",
    "        new_df = new_df.append(new_row, ignore_index=True)\n",
    "    new_df = new_df.fillna(0)\n",
    "    new_df['case_id'] = new_df['case_id'].apply(lambda x: int(x))\n",
    "    return new_df\n",
    "\n",
    "def get_nearest_neighbors(df, n_neighbors, nn_model):\n",
    "    knearest = nn_model.kneighbors(n_neighbors=n_neighbors, return_distance=False)\n",
    "    for k in range(n_neighbors):\n",
    "        df[f'nn_{k}'] = [df.case_id[x[k]] for x in knearest]\n",
    "        \n",
    "def edge_length(row, k, graph):\n",
    "    return nx.shortest_path_length(graph, row['case_id'], row[f'nn_{k}'])\n",
    "\n",
    "def get_edge_lengths(df, n_neighbors, graph):\n",
    "    for k in range(n_neighbors):\n",
    "        df[f'cite_distance_{k}'] = df.apply(edge_length, k=k, graph=graph, axis=1)\n",
    "        \n",
    "def get_min_cite_dist(row, n_neighbors):\n",
    "    return int(row[[f'cite_distance_{k}' for k in range(n_neighbors)]].min())\n",
    "\n",
    "def get_mean_cite_dist(row, n_neighbors):\n",
    "    return row[[f'cite_distance_{k}' for k in range(n_neighbors)]].mean()\n",
    "\n",
    "def get_max_cite_dist(row, n_neighbors):\n",
    "    return int(row[[f'cite_distance_{k}' for k in range(n_neighbors)]].max())\n",
    "\n",
    "def knn_citation_validation(test_ids, lda_model, test_corpus, graph, n_neighbors, num_topics=15):\n",
    "    test_data = pd.DataFrame(test_ids, columns=['case_id'])\n",
    "    test_data['topic_vector'] = [lda_model[op] for op in test_corpus]\n",
    "    nodes = list(graph.nodes)\n",
    "    test_data = test_data.loc[test_data.case_id.isin(nodes),:]\n",
    "    nodes = None\n",
    "    test_data.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    test_data = unpack_topics(test_data, num_topics=num_topics)\n",
    "    \n",
    "    nn = NearestNeighbors()\n",
    "\n",
    "    X = test_data.drop(columns='case_id').values\n",
    "\n",
    "    nn.fit(X)\n",
    "    \n",
    "    get_nearest_neighbors(test_data, n_neighbors, nn)\n",
    "    \n",
    "    get_edge_lengths(test_data, n_neighbors, graph)\n",
    "    \n",
    "    test_data['min_cite_dist'] = test_data.apply(get_min_cite_dist, axis=1, n_neighbors=n_neighbors)\n",
    "    test_data['mean_cite_dist'] = test_data.apply(get_mean_cite_dist, axis=1, n_neighbors=n_neighbors)\n",
    "    test_data['max_cite_dist'] = test_data.apply(get_max_cite_dist, axis=1, n_neighbors=n_neighbors)\n",
    "    \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain largest connected component of citation graph and other static variables.\n",
    "\n",
    "G = nx.read_gpickle(graph_path)\n",
    "big_subgraph = nx.subgraph(G, list(nx.connected_components(G))[0])\n",
    "G = None\n",
    "seed = 9\n",
    "num_topics = [5, 8, 10, 12, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOPIC MODELING AND VALIDATION\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f'BEGINNING VALIDATION OF {dataset}...')\n",
    "    data = pd.read_csv(os.path.join(processed_data_header, dataset + '_processed.csv'))\n",
    "    parse_list_col(data, 'opinion')\n",
    "    \n",
    "    # Shuffle data to ensure jurisdictions are mixed properly.\n",
    "\n",
    "    data = data.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "    # Split into train/test sets\n",
    "\n",
    "    split = int(0.8*data.shape[0])\n",
    "    train_ops = data.loc[:split, 'opinion']\n",
    "    test_ops = data.loc[split:, 'opinion']\n",
    "\n",
    "    # Build gensim dictionary\n",
    "\n",
    "    op_dictionary = Dictionary(train_ops.to_list())\n",
    "    train_op_corpus = [op_dictionary.doc2bow(op) for op in train_ops.to_list()]\n",
    "    test_op_corpus = [op_dictionary.doc2bow(op) for op in test_ops.to_list()]\n",
    "    \n",
    "    # BEGIN VALIDATION. THIS WILL TAKE SOME TIME.\n",
    "\n",
    "    train_perplexity = []\n",
    "    test_perplexity = []\n",
    "    train_coherence = []\n",
    "    test_coherence = []\n",
    "    min_cite_dist_mean = []\n",
    "    min_cite_dist_sd = []\n",
    "    avg_cite_dist_mean = []\n",
    "    avg_cite_dist_sd = []\n",
    "    max_cite_dist_mean = []\n",
    "    max_cite_dist_sd = []\n",
    "\n",
    "    test_ids = data.loc[split:, 'case_id'].to_list()\n",
    "    data = None\n",
    "\n",
    "    wordcloud_header = os.path.join(wordcloud_header_top, dataset)\n",
    "    os.mkdir(wordcloud_header)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for nt in num_topics:\n",
    "        iter_start=time.time()\n",
    "        print(f'Processing model with {nt} topics...')\n",
    "        temp_time= time.time()\n",
    "        lda = LdaModel(train_op_corpus, id2word=op_dictionary, num_topics=nt)\n",
    "        print(f'Model training done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing perplexity on train set.')\n",
    "        temp_time= time.time()\n",
    "        train_perplexity.append(get_perplexity(lda, train_op_corpus))\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing perplexity on test set.')\n",
    "        temp_time= time.time()\n",
    "        test_perplexity.append(get_perplexity(lda, test_op_corpus))\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing coherence on train set.')\n",
    "        temp_time= time.time()\n",
    "        train_coherence.append(get_coherence(lda, train_ops.to_list(), op_dictionary))\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing coherence on test set.')\n",
    "        temp_time= time.time()\n",
    "        test_coherence.append(get_coherence(lda, test_ops.to_list(), op_dictionary))\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Computing citation graph validation metrics.')\n",
    "        temp_time= time.time()\n",
    "        metric_cols = ['min_cite_dist', 'mean_cite_dist', 'max_cite_dist']\n",
    "        citation_dist_results = knn_citation_validation(test_ids, lda, test_op_corpus, big_subgraph, 5, nt)[metric_cols]\n",
    "        min_cite_dist_mean.append(citation_dist_results.min_cite_dist.mean())\n",
    "        min_cite_dist_sd.append(citation_dist_results.min_cite_dist.std())\n",
    "        avg_cite_dist_mean.append(citation_dist_results.mean_cite_dist.mean())\n",
    "        avg_cite_dist_sd.append(citation_dist_results.mean_cite_dist.std())\n",
    "        max_cite_dist_mean.append(citation_dist_results.max_cite_dist.mean())\n",
    "        max_cite_dist_sd.append(citation_dist_results.max_cite_dist.std())\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print('Saving wordclouds...')\n",
    "        temp_time= time.time()\n",
    "        os.mkdir(os.path.join(wordcloud_header, f'num_topics_{nt}'))\n",
    "        get_wordclouds(lda, save_file=os.path.join(wordcloud_header, f'num_topics_{nt}'), num_topics=nt)\n",
    "        print(f'Done. Time: {round(time.time()-temp_time)}')\n",
    "        print(f'Done with full iteration. TOTAL TIME: {round(time.time()-iter_start)}')\n",
    "        print('######################################')\n",
    "    print(f'FINISHED. TOTAL TIME ELAPSED: {time.time()-start}')\n",
    "\n",
    "    results_df = pd.DataFrame({'num_topics': num_topics,\n",
    "                              'train_perplexity': train_perplexity,\n",
    "                              'test_perplexity': test_perplexity,\n",
    "                              'train_coherence': train_coherence,\n",
    "                              'test_coherence': test_coherence,\n",
    "                              'min_cite_dist_mean': min_cite_dist_mean,\n",
    "                              'min_cite_dist_sd': min_cite_dist_sd,\n",
    "                              'avg_cite_dist_mean': avg_cite_dist_mean,\n",
    "                              'avg_cite_dist_sd': avg_cite_dist_sd,\n",
    "                              'max_cite_dist_mean': max_cite_dist_mean,\n",
    "                              'max_cite_dist_sd': max_cite_dist_sd})\n",
    "\n",
    "    results_df.to_csv(os.path.join(output_header, dataset + '.csv'), index=False)\n",
    "\n",
    "    train_ops = None\n",
    "    train_op_corpus = None\n",
    "    test_ops = None\n",
    "    test_op_corpus = None\n",
    "    op_dictionary = None\n",
    "    test_ids = None\n",
    "results_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF MULTIPLE DATASETS HAVE BEEN PREPROCESSED, MODIFY THIS CODE TO COMPARE.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "results_header = '/Users/jhamer90811/Documents/Insight/legal_topic_modeling/validation_output/basic_stopwords_nouns_verbs_12k'\n",
    "\n",
    "\n",
    "datasets = ['cases_IL_after1950_12k']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "for dataset in datasets:\n",
    "    new_data = pd.read_csv(os.path.join(results_header, dataset + '.csv'))\n",
    "    new_data['name'] = dataset\n",
    "    data = data.append(new_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train perplexity\n",
    "ax = sns.lineplot('num_topics', 'train_perplexity', hue='name', data=data)\n",
    "ax.set_title('Train Perplexity vs. Number of Topics; by Input Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test perplexity\n",
    "ax = sns.lineplot('num_topics', 'test_perplexity', hue='name', data=data)\n",
    "ax.set_title('Test Perplexity vs. Number of Topics; by Input Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train coherence\n",
    "ax = sns.lineplot('num_topics', 'train_coherence', hue='name', data=data)\n",
    "ax.set_title('Train Coherence vs. Number of Topics; by Input Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test coherence\n",
    "ax = sns.lineplot('num_topics', 'test_coherence', hue='name', data=data)\n",
    "ax.set_title('Test Coherence vs. Number of Topics; by Input Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min citation distance\n",
    "ax = sns.lineplot('num_topics', 'min_cite_dist_mean', hue='name', data=data)\n",
    "ax.set_title('Min Citation Distance vs. Number of Topics; by Input Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average citation distance\n",
    "ax = sns.lineplot('num_topics', 'avg_cite_dist_mean', hue='name', data=data)\n",
    "ax.set_title('Avg Citation Distance vs. Number of Topics; by Input Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum citation distance\n",
    "ax = sns.lineplot('num_topics', 'max_cite_dist_mean', hue='name', data=data)\n",
    "ax.set_title('Max Citation Distance vs. Number of Topics; by Input Dataset')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
